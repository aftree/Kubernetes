<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>使用 kubeadm 引导集群 on Hugo 主题的 Learn 文档</title>
    <link>https://lijun.in/setup/production-environment/tools/kubeadm/</link>
    <description>Recent content in 使用 kubeadm 引导集群 on Hugo 主题的 Learn 文档</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    
	<atom:link href="https://lijun.in/setup/production-environment/tools/kubeadm/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>安装 kubeadm</title>
      <link>https://lijun.in/setup/production-environment/tools/kubeadm/install-kubeadm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lijun.in/setup/production-environment/tools/kubeadm/install-kubeadm/</guid>
      <description>本页面显示如何安装 kubeadm 工具箱。 有关在执行此安装过程后如何使用 kubeadm 创建集群的信息，请参见使用 kubeadm 创建集群 页面。
. heading &amp;ldquo;prerequisites&amp;rdquo; %}}  一台或多台运行着下列系统的机器：  Ubuntu 16.04+ Debian 9+ CentOS 7 Red Hat Enterprise Linux (RHEL) 7 Fedora 25+ HypriotOS v1.0.1+ Container Linux (测试 1800.6.0 版本)   每台机器 2 GB 或更多的 RAM (如果少于这个数字将会影响您应用的运行内存) 2 CPU 核或更多 集群中的所有机器的网络彼此均能相互连接(公网和内网都可以) 节点之中不可以有重复的主机名、MAC 地址或 product_uuid。请参见这里 了解更多详细信息。 开启机器上的某些端口。请参见这里 了解更多详细信息。 禁用交换分区。为了保证 kubelet 正常工作，您 必须 禁用交换分区。  确保每个节点上 MAC 地址和 product_uuid 的唯一性  您可以使用命令 ip link 或 ifconfig -a 来获取网络接口的 MAC 地址 可以使用 sudo cat /sys/class/dmi/id/product_uuid 命令对 product_uuid 校验  一般来讲，硬件设备会拥有唯一的地址，但是有些虚拟机的地址可能会重复。Kubernetes 使用这些值来唯一确定集群中的节点。 如果这些值在每个节点上不唯一，可能会导致安装失败。</description>
    </item>
    
    <item>
      <title>对 kubeadm 进行故障排查</title>
      <link>https://lijun.in/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lijun.in/setup/production-environment/tools/kubeadm/troubleshooting-kubeadm/</guid>
      <description>与任何程序一样，您可能会在安装或者运行 kubeadm 时遇到错误。 本文列举了一些常见的故障场景，并提供可帮助您理解和解决这些问题的步骤。
如果您的问题未在下面列出，请执行以下步骤：
  如果您认为问题是 kubeadm 的错误：
 转到 github.com/kubernetes/kubeadm 并搜索存在的问题。 如果没有问题，请 打开 并遵循问题模板。    如果您对 kubeadm 的工作方式有疑问，可以在 Slack 上的 #kubeadm 频道提问， 或者在 StackOverflow 上提问。 请加入相关标签，例如 #kubernetes 和 #kubeadm，这样其他人可以帮助您。
  在安装过程中没有找到 ebtables 或者其他类似的可执行文件 如果在运行 kubeadm init 命令时，遇到以下的警告
[preflight] WARNING: ebtables not found in system path [preflight] WARNING: ethtool not found in system path 那么或许在您的节点上缺失 ebtables、ethtool 或者类似的可执行文件。 您可以使用以下命令安装它们：
 对于 Ubuntu/Debian 用户，运行 apt install ebtables ethtool 命令。 对于 CentOS/Fedora 用户，运行 yum install ebtables ethtool 命令。  在安装过程中，kubeadm 一直等待控制平面就绪 如果您注意到 kubeadm init 在打印以下行后挂起：</description>
    </item>
    
    <item>
      <title>使用 kubeadm 定制控制平面配置</title>
      <link>https://lijun.in/setup/production-environment/tools/kubeadm/control-plane-flags/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lijun.in/setup/production-environment/tools/kubeadm/control-plane-flags/</guid>
      <description>. feature-state for_k8s_version=&amp;quot;1.12&amp;rdquo; state=&amp;quot;stable&amp;rdquo; &amp;gt;}}
kubeadm ClusterConfiguration 对象公开了 extraArgs 字段，它可以覆盖传递给控制平面组件（如 APIServer、ControllerManager 和 Scheduler）的默认参数。各组件配置使用如下字段定义：
 apiServer controllerManager scheduler  extraArgs 字段由 key: value 对组成。 要覆盖控制平面组件的参数:
 将适当的字段添加到配置中。 向字段添加要覆盖的参数值。 用 --config &amp;lt;YOUR CONFIG YAML&amp;gt; 运行 kubeadm init。  有关配置中的每个字段的详细信息，您可以导航到我们的 API 参考页面。
. note &amp;gt;}}
您可以通过运行 kubeadm config print init-defaults 并将输出保存到您选择的文件中，以默认值形式生成 ClusterConfiguration 对象。 . /note &amp;gt;}}
APIServer 参数 有关详细信息，请参阅 kube-apiserver 参考文档。
使用示例：
apiVersion: kubeadm.k8s.io/v1beta2 kind: ClusterConfiguration kubernetesVersion: v1.16.0 apiServer: extraArgs: advertise-address: 192.168.0.103 anonymous-auth: &amp;#34;false&amp;#34; enable-admission-plugins: AlwaysPullImages,DefaultStorageClass audit-log-path: /home/johndoe/audit.</description>
    </item>
    
    <item>
      <title>高可用拓扑选项</title>
      <link>https://lijun.in/setup/production-environment/tools/kubeadm/ha-topology/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lijun.in/setup/production-environment/tools/kubeadm/ha-topology/</guid>
      <description>本页面介绍了配置高可用（HA） Kubernetes 集群拓扑的两个选项。
您可以设置 HA 集群：
 使用堆叠（stacked）控制平面节点，其中 etcd 节点与控制平面节点共存 使用外部 etcd 节点，其中 etcd 在与控制平面不同的节点上运行  在设置 HA 集群之前，您应该仔细考虑每种拓扑的优缺点。
. note &amp;gt;}} kubeadm 静态引导 etcd 集群。 阅读 etcd 集群指南以获得更多详细信息。 . /note &amp;gt;}}
堆叠（Stacked） etcd 拓扑 堆叠（Stacked） HA 集群是一种这样的拓扑，其中 etcd 分布式数据存储集群堆叠在 kubeadm 管理的控制平面节点上，作为控制平面的一个组件运行。
每个控制平面节点运行 kube-apiserver，kube-scheduler 和 kube-controller-manager 实例。
kube-apiserver 使用负载均衡器暴露给工作节点。
每个控制平面节点创建一个本地 etcd 成员（member），这个 etcd 成员只与该节点的 kube-apiserver 通信。这同样适用于本地 kube-controller-manager 和 kube-scheduler 实例。
这种拓扑将控制平面和 etcd 成员耦合在同一节点上。相对使用外部 etcd 集群，设置起来更简单，而且更易于副本管理。
然而，堆叠集群存在耦合失败的风险。如果一个节点发生故障，则 etcd 成员和控制平面实例都将丢失，并且冗余会受到影响。您可以通过添加更多控制平面节点来降低此风险。
因此，您应该为 HA 集群运行至少三个堆叠的控制平面节点。</description>
    </item>
    
    <item>
      <title>利用 kubeadm 创建高可用集群</title>
      <link>https://lijun.in/setup/production-environment/tools/kubeadm/high-availability/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lijun.in/setup/production-environment/tools/kubeadm/high-availability/</guid>
      <description>本文讲述了使用 kubeadm 设置一个高可用的 Kubernetes 集群的两种不同方式：
 使用堆控制平面节点。这种方法所需基础设施较少。etcd 成员和控制平面节点位于同一位置。 使用外部集群。这种方法所需基础设施较多。控制平面的节点和 etcd 成员是分开的。  在下一步之前，您应该仔细考虑哪种方法更好的满足您的应用程序和环境的需求。 这是对比文档 讲述了每种方法的优缺点。
如果您在安装 HA 集群时遇到问题，请在 kubeadm 问题跟踪里向我们提供反馈。
您也可以阅读 升级文件。
. caution &amp;gt;}} 这篇文档没有讲述在云提供商上运行集群的问题。在云环境中，此处记录的方法不适用于类型为 LoadBalancer 的服务对象，或者具有动态的 PersistentVolumes。 . /caution &amp;gt;}}
. heading &amp;ldquo;prerequisites&amp;rdquo; %}} 对于这两种方法，您都需要以下基础设施：
 配置三台机器kubeadm 的最低要求给主节点 配置三台机器 kubeadm 的最低要求 给工作节点 在集群中，所有计算机之间的完全网络连接（公网或私网） 所有机器上的 sudo 权限 每台设备对系统中所有节点的 SSH 访问 在所有机器上安装 kubeadm 和 kubelet，kubectl 是可选的。  仅对于外部 etcd 集群来说，您还需要：
 给 etcd 成员使用的另外三台机器  这两种方法的第一步 为 kube-apiserver 创建负载均衡器 . note &amp;gt;}} 使用负载均衡器需要许多配置。您的集群搭建可能需要不同的配置。下面的例子只是其中的一方面配置。 .</description>
    </item>
    
    <item>
      <title>使用 kubeadm 创建一个高可用 etcd 集群</title>
      <link>https://lijun.in/setup/production-environment/tools/kubeadm/setup-ha-etcd-with-kubeadm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lijun.in/setup/production-environment/tools/kubeadm/setup-ha-etcd-with-kubeadm/</guid>
      <description>. note &amp;gt;}}
在本指南中，当 kubeadm 用作为外部 etcd 节点管理工具，请注意 kubeadm 不计划支持此类节点的证书更换或升级。对于长期规划是使用 etcdadm 增强工具来管理这方面。 . /note &amp;gt;}}
默认情况下，kubeadm 运行单成员的 etcd 集群，该集群由控制面节点上的 kubelet 以静态 Pod 的方式进行管理。由于 etcd 集群只包含一个成员且不能在任一成员不可用时保持运行，所以这不是一种高可用设置。本任务，将告诉您如何在使用 kubeadm 创建一个 kubernetes 集群时创建一个外部 etcd：有三个成员的高可用 etcd 集群。
. heading &amp;ldquo;prerequisites&amp;rdquo; %}}  三个可以通过 2379 和 2380 端口相互通信的主机。本文档使用这些作为默认端口。不过，它们可以通过 kubeadm 的配置文件进行自定义。   每个主机必须 安装有 docker、kubelet 和 kubeadm。   一些可以用来在主机间复制文件的基础设施。例如 ssh 和 scp 就可以满足需求。  建立集群 一般来说，是在一个节点上生成所有证书并且只分发这些必要的文件到其它节点上。
. note &amp;gt;}}
kubeadm 包含生成下述证书所需的所有必要的密码学工具；在这个例子中，不需要其他加密工具。 . /note &amp;gt;}}
  将 kubelet 配置为 etcd 的服务管理器。</description>
    </item>
    
    <item>
      <title>使用 kubeadm 配置集群中的每个 kubelet</title>
      <link>https://lijun.in/setup/production-environment/tools/kubeadm/kubelet-integration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lijun.in/setup/production-environment/tools/kubeadm/kubelet-integration/</guid>
      <description>. feature-state for_k8s_version=&amp;quot;1.11&amp;rdquo; state=&amp;quot;stable&amp;rdquo; &amp;gt;}}
kubeadm CLI 工具的生命周期与 kubelet解耦，它是一个守护程序，在 Kubernetes 集群中的每个节点上运行。 当 Kubernetes 初始化或升级时，kubeadm CLI 工具由用户执行，而 kubelet 始终在后台运行。
由于kubelet是守护程序，因此需要通过某种初始化系统或服务管理器进行维护。 当使用 DEB 或 RPM 安装 kubelet 时，配置系统去管理 kubelet。 您可以改用其他服务管理器，但需要手动地配置。
集群中涉及的所有 kubelet 的一些配置细节都必须相同，而其他配置方面则需要基于每个 kubelet 进行设置，以适应给定机器的不同特性，例如操作系统、存储和网络。 您可以手动地管理 kubelet 的配置，但是 kubeadm 现在提供一种 KubeletConfiguration API 类型，用于集中管理 kubelet 的配置。
Kubelet 配置模式 以下各节讲述了通过使用 kubeadm 简化 kubelet 配置模式，而不是在每个节点上手动地管理 kubelet 配置。
将集群级配置传播到每个 kubelet 中 您可以通过使用 kubeadm init 和 kubeadm join 命令为 kubelet 提供默认值。 有趣的示例包括使用其他 CRI 运行时或通过服务器设置不同的默认子网。
如果您想使用子网 10.96.0.0/12 作为默认的服务，您可以给 kubeadm 传递 --service-cidr 参数：</description>
    </item>
    
    <item>
      <title>配置您的 kubernetes 集群以自托管控制平台</title>
      <link>https://lijun.in/setup/production-environment/tools/kubeadm/self-hosting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://lijun.in/setup/production-environment/tools/kubeadm/self-hosting/</guid>
      <description>自托管 Kubernetes 控制平台 kubeadm 允许您实验性地创建 self-hosted Kubernetes 控制平面。 这意味着 API 服务器，控制管理器和调度程序之类的关键组件将通过配置 Kubernetes API 以 DaemonSet pods 的身份运行，而不是通过静态文件将 static pods 在 kubelet 中配置。
要创建自托管集群，请参见 kubeadm alpha 自托管枢纽 命令。
警告 . caution &amp;gt;}}
此功能将您的集群设置为不受支持的状态，从而使 kubeadm 无法再管理您的集群。 这包括 kubeadm 升级 。 . /caution &amp;gt;}}
 1.8及更高版本中的自托管功能有一些重要限制。 特别是，自托管集群在没有人工干预的情况下_无法从控制平面节点的重新启动中恢复_ 。   默认情况下，自托管的控制平面 Pod 依赖于从 hostPath 卷加载的凭据。 除初始创建外，这些凭据不由 kubeadm 管理。   控制平面的自托管部分不包括 etcd，后者仍作为静态 Pod 运行。  处理 自托管引导过程记录在 kubeadm 设计文档 中。
总而言之，kubeadm alpha 自托管 的工作原理如下：</description>
    </item>
    
  </channel>
</rss>